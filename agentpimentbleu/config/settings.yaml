# AgentPimentBleu Configuration Template

# LLM Providers Configuration
llm_providers:
  gemini:
    api_key: 'YOUR_GEMINI_API_KEY'
    model: 'gemini-2.0-flash'
  ollama:
    base_url: 'http://localhost:11434'
    model: 'llama3.2:1b'
  mistral:
    api_key: 'YOUR_MISTRAL_API_KEY'
    model: 'devstral-small-2505'

# Default LLM provider to use when none is specified
default_llm_provider: 'gemini'

# Dependency Parsers Configuration
dependency_parsers:
  python_manifests:
    - 'requirements.txt'
    - 'Pipfile'
    - 'poetry.lock'
  javascript_manifests:
    - 'package.json'
    - 'package-lock.json'
    - 'yarn.lock'

# RAG Settings
rag_settings:
  embedding_model: 'local'
  chunk_size: 1024
  # Use ~/.cache/agentpimentbleu/models by default (for local installation)
  # This will be overridden to /app/.cache/agentpimentbleu/models in Docker
  # via the APB_RAG_SETTINGS__CACHE_DIR environment variable
  cache_dir: '~/.cache/agentpimentbleu/models'
